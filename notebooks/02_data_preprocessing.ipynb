{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "## Import the preprocessing function\n",
    "from src.data_preprocessing import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in FraudResult before dropping: 0\n",
      "Number of rows after dropping NaN in FraudResult: 95662\n",
      "Number of NaN values in FraudResult after converting to numeric: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the training data and check for NaN in FraudResult\n",
    "train_data_path = '../data/training.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "print(\"Number of NaN values in FraudResult before dropping:\", train_data['FraudResult'].isna().sum())\n",
    "\n",
    "# Drop rows with NaN in FraudResult\n",
    "train_data = train_data.dropna(subset=['FraudResult'])\n",
    "print(\"Number of rows after dropping NaN in FraudResult:\", len(train_data))\n",
    "\n",
    "# Ensure FraudResult is numeric\n",
    "train_data['FraudResult'] = pd.to_numeric(train_data['FraudResult'], errors='coerce')\n",
    "print(\"Number of NaN values in FraudResult after converting to numeric:\", train_data['FraudResult'].isna().sum())\n",
    "\n",
    "# Save the cleaned training data\n",
    "train_data.to_csv('../data/cleaned_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the cleaned training data\n",
    "(X_train, y_train, X_val, y_val, feature_names, preprocessor) = preprocess_data('../data/cleaned_training.csv', is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute the amount threshold\n",
    "amount_threshold = train_data['Amount'].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominic/Downloads/Nexford_University/Applied Machine Learning for Analytics/final_project/xente-fraud-detection-challenge/venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Preprocess the test data\n",
    "test_data_path = '../data/test.csv'\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Apply the same preprocessing steps (without fitting)\n",
    "test_data = test_data.drop(columns=['Value'])\n",
    "drop_cols = ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId']\n",
    "test_data = test_data.drop(columns=drop_cols)\n",
    "\n",
    "# Feature Engineering\n",
    "test_data['TransactionStartTime'] = pd.to_datetime(test_data['TransactionStartTime'])\n",
    "test_data['hour'] = test_data['TransactionStartTime'].dt.hour\n",
    "test_data['day_of_week'] = test_data['TransactionStartTime'].dt.dayofweek\n",
    "test_data['month'] = test_data['TransactionStartTime'].dt.month\n",
    "test_data = test_data.drop(columns=['TransactionStartTime'])\n",
    "\n",
    "test_data['log_amount'] = np.log1p(test_data['Amount'].abs() + 1)\n",
    "test_data['high_amount_flag'] = (test_data['Amount'] > amount_threshold).astype(int)\n",
    "test_data['high_fraud_provider'] = test_data['ProviderId'].isin(['ProviderId_1', 'ProviderId_3', 'ProviderId_5']).astype(int)\n",
    "test_data['high_fraud_channel'] = test_data['ChannelId'].isin(['ChannelId_1', 'ChannelId_3', 'ChannelId_2']).astype(int)\n",
    "high_fraud_categories = ['transport', 'utility_bill', 'financial_services']\n",
    "test_data['high_fraud_category'] = test_data['ProductCategory'].isin(high_fraud_categories).astype(int)\n",
    "\n",
    "# Transform test data using the fitted preprocessor\n",
    "X_test_processed = preprocessor.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in y_val before saving: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Save the preprocessed data and preprocessing objects\n",
    "# Save training and validation splits as DataFrames\n",
    "X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "X_train_df['FraudResult'] = y_train\n",
    "X_train_df.to_csv('../data/preprocessed_train.csv', index=False)\n",
    "\n",
    "# Debug: Check for NaN in y_val before saving\n",
    "print(\"Number of NaN values in y_val before saving:\", y_val.isna().sum())\n",
    "X_val_df = pd.DataFrame(X_val, columns=feature_names)\n",
    "X_val_df['FraudResult'] = y_val\n",
    "X_val_df.to_csv('../data/preprocessed_val.csv', index=False)\n",
    "\n",
    "# Save preprocessed test data (no FraudResult column since test data doesn't have it)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "X_test_df.to_csv('../data/preprocessed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_val_df: 19133\n",
      "Length of y_val: 19133\n",
      "Number of NaN values in X_val_df['FraudResult'] after assignment: 0\n",
      "Unique values in X_val_df['FraudResult'] after assignment: [0 1]\n",
      "Number of NaN values in preprocessed_val.csv after saving: 0\n",
      "Unique values in preprocessed_val.csv['FraudResult'] after loading: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# # Debug: Check for NaN in y_val before saving\n",
    "# print(\"Number of NaN values in y_val before saving:\", y_val.isna().sum())\n",
    "# # Convert y_val to integer to avoid floating-point issues\n",
    "# y_val = pd.Series(y_val).astype(int)\n",
    "# X_val_df = pd.DataFrame(X_val, columns=feature_names)\n",
    "# Reset indices to ensure alignment\n",
    "X_val_df = X_val_df.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "# Debug: Check lengths before assignment\n",
    "print(\"Length of X_val_df:\", len(X_val_df))\n",
    "print(\"Length of y_val:\", len(y_val))\n",
    "# Check if lengths match\n",
    "if len(X_val_df) != len(y_val):\n",
    "    raise ValueError(\"Length mismatch between X_val_df and y_val!\")\n",
    "X_val_df['FraudResult'] = y_val\n",
    "# Debug: Check for NaN and unique values after assignment\n",
    "print(\"Number of NaN values in X_val_df['FraudResult'] after assignment:\", X_val_df['FraudResult'].isna().sum())\n",
    "print(\"Unique values in X_val_df['FraudResult'] after assignment:\", X_val_df['FraudResult'].unique())\n",
    "X_val_df.to_csv('../data/preprocessed_val.csv', index=False)\n",
    "\n",
    "# Debug: Reload preprocessed_val.csv to check for NaN and unique values\n",
    "val_data_check = pd.read_csv('../data/preprocessed_val.csv', dtype={'FraudResult': int})\n",
    "print(\"Number of NaN values in preprocessed_val.csv after saving:\", val_data_check['FraudResult'].isna().sum())\n",
    "print(\"Unique values in preprocessed_val.csv['FraudResult'] after loading:\", val_data_check['FraudResult'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed test data (no FraudResult column since test data doesn't have it)\n",
    "X_test_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "X_test_df.to_csv('../data/preprocessed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed. Saved preprocessed_train.csv, preprocessed_val.csv, preprocessed_test.csv, amount_threshold, preprocessor, and feature_names.\n"
     ]
    }
   ],
   "source": [
    "# Save the amount_threshold, preprocessor, and feature_names\n",
    "joblib.dump(amount_threshold, '../models/amount_threshold.joblib')\n",
    "joblib.dump(preprocessor, '../models/preprocessor.joblib')\n",
    "joblib.dump(feature_names, '../models/feature_names.joblib')\n",
    "\n",
    "print(\"Preprocessing completed. Saved preprocessed_train.csv, preprocessed_val.csv, preprocessed_test.csv, amount_threshold, preprocessor, and feature_names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xente-env)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
